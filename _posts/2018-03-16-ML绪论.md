---
layout:     post
title:      "ML绪论"
subtitle:   “未完待续，持续更新中"
date:       2018-03-16 08:00:00
author:     "guanglinzhou"
header-img: "img/post-bg-2015.jpg"
tags:
    - ML
---

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>


----------

机器学习是计算机通过学习算法从数据中产生模型。
机器学习使用的数据集一般可以表示为$$$m*n$$$的矩阵，每条记录称为样本，每列称为属性。
属性张成的空间称为`样本空间`。得到的训练集只是样本空间的一个子集。
机器学习的目标是使学得的模型能够很好地适用于“新样本”，适用于新样本的能力称为”泛化能力“。
`泛化的本质`是希望在训练集上生成的模型，能够最大限度的适用于整个样本空间。

> 为什么需要的数据量越大泛化能力越好？ 因为通常假设样本空间是服从一个分布的（当然这个分布是未知的，不然还学习个毛线），获得的每个样本都是独立地从这个分布上获得，称为`独立同分布`，所以样本量越大，对样本空间的分布信息越多，泛化能力越好。

**没有免费午餐定律：**在所有可能的分布上平均之后，每个学习算法在新样本上的期望性能相同。
说明，结合具体问题具体分析，不存在**什么算法更好**这种言论。
在具体问题上，会人为的对遇到的概率分布进行假设，然后应用在**假设分布**上效果更好的学习算法。


----------

模型参数(数据学习到的)和模型超参数(人工设定)的区别。


训练后得到的模型，需要评估其性能，常用的评估方法有：
- 留出法（将数据集分为训练和测试集）
- 交叉验证法（k-fold交叉验证）
- 自助采样法：对于包含$$$m$$$个样本的初始数据集$$$D$$$，随机有放回的取一个样本放入采样数据集$$$D'$$$中，重复$$$m$$$次，以$$$D'$$$作为训练集，$$$D-D'$$$作为测试集。（相比于留出法和交叉验证，自助法可以保持训练集的大小仍然等于初始数据集大小$$$m$$$，而测试集大小大约为$$$0.368m$$$）。`自助法一般在样本量比较少的时候使用，但是自助法产生的数据集会改变初始数据集的分布，引起估计偏差，在样本量较大时，一般采样留出法和交叉验证。`


在训练模型时评估其在验证集上的性能，同时调整模型的参数。
参数分为两种：
- 模型超参数：（数目较少，人工设定），一般通过网格搜索调节，常见的有，学习率，sub-sample，max-deepth等；
- 模型参数：（数目较大，从数据中学习得到），常见的有神经网络的权重系数，线性模型的系数等。


----------
